{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1727b61",
   "metadata": {},
   "source": [
    "# Nyaya Staging Review Notebook\n",
    "A compact UI to pretty‑print and review Nyaya‑style argument records, approve/disapprove/edit them, persist decisions, and prepare approved clean JSONL snapshots per round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ddbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Setup: Install and Import Libraries\n",
    "import sys, json, uuid, copy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# Optional installs (skip if already available)\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"pandas is required for this notebook\")\n",
    "\n",
    "try:\n",
    "    from ipywidgets import Button, Textarea, Output, HBox, VBox, IntProgress, Label\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"ipywidgets is required. In VS Code, enable the Jupyter extension and ipywidgets support.\")\n",
    "\n",
    "try:\n",
    "    from rich.console import Console\n",
    "    from rich.panel import Panel\n",
    "    from rich.text import Text\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"rich is required for pretty printing\")\n",
    "\n",
    "console = Console(record=True)\n",
    "\n",
    "# Paths\n",
    "WORKDIR = Path('nyaya')\n",
    "RUNS_DIR = WORKDIR / 'runs'\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SOURCES_DIR = WORKDIR / 'Datasets' / 'sources'\n",
    "ROUND_DIR = WORKDIR / 'Datasets' / 'rounds' / 'staging_round_0001'\n",
    "ROUND_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TIMESTAMP = datetime.utcnow().strftime('%Y%m%d_%H%M%S')\n",
    "SESSION_DIR = RUNS_DIR / f'review_{TIMESTAMP}'\n",
    "SESSION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LEDGER_PATH = SESSION_DIR / 'ledger.jsonl'\n",
    "SNAPSHOT_CSV = SESSION_DIR / 'records_snapshot.csv'\n",
    "APPROVED_OUT = ROUND_DIR / 'approved_snapshot_clean.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Schema and Validation\n",
    "REQUIRED_FIELDS = [\n",
    "    'domain','pratijna','hetu','udaharana','upanaya','nigamana','grounding_authority'\n",
    "]\n",
    "\n",
    "STATUSES = {'queued','approved','disapproved','edited'}\n",
    "\n",
    "def normalize_text(s: Optional[str]) -> str:\n",
    "    if s is None: return ''\n",
    "    return ' '.join(str(s).strip().split())\n",
    "\n",
    "def validate_record(r: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    rec = {k: normalize_text(r.get(k)) for k in REQUIRED_FIELDS}\n",
    "    # carry optional fields\n",
    "    rec['source'] = r.get('source')\n",
    "    rec['notes'] = r.get('notes', '')\n",
    "    # id and status\n",
    "    rec['id'] = r.get('id') or str(uuid.uuid4())\n",
    "    status = r.get('status') or 'queued'\n",
    "    rec['status'] = status if status in STATUSES else 'queued'\n",
    "    rec['history'] = r.get('history') or []\n",
    "    # simple asserts\n",
    "    missing = [k for k in REQUIRED_FIELDS if not rec[k]]\n",
    "    if missing:\n",
    "        rec['status'] = 'queued'\n",
    "        rec.setdefault('notes','')\n",
    "        rec['notes'] += f\" | Missing fields: {missing}\"\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load Seed Data (paste JSON array) and optional source notes\n",
    "SEED_JSON = [\n",
    "  {\n",
    "    \"domain\": \"Literary History / Indology\",\n",
    "    \"pratijna\": \"The Hanuman Chalisa was composed by Tulsidas in the 16th century CE.\",\n",
    "    \"hetu\": \"Because this attribution is firmly established by a continuous literary tradition and the scholarly consensus.\",\n",
    "    \"udaharana\": \"The authorship and period of a major literary work are determined by historical records, manuscript traditions, and scholarly consensus, just as the plays of Kālidāsa are attributed to him based on the historical and literary record of the Gupta period.\",\n",
    "    \"upanaya\": \"The Hanuman Chalisa is such a work, consistently attributed to Tulsidas within the Bhakti literary tradition and by modern historical scholarship, placing him in the 16th century.\",\n",
    "    \"nigamana\": \"Therefore, the Hanuman Chalisa was composed by Tulsidas in the 16th century CE.\",\n",
    "    \"grounding_authority\": \"Historical Record & Literary Scholarly Consensus\"\n",
    "  },\n",
    "  {\n",
    "    \"domain\": \"Historical Linguistics\",\n",
    "    \"pratijna\": \"The Hanuman Chalisa is written in the Awadhi language.\",\n",
    "    \"hetu\": \"Because its grammar, vocabulary, and phonology are characteristic of Awadhi.\",\n",
    "    \"udaharana\": \"The language of any text is identified by its specific linguistic features, just as the Canterbury Tales is identified as being written in Middle English due to its distinct grammar, vocabulary, and phonology.\",\n",
    "    \"upanaya\": \"The Hanuman Chalisa exhibits these specific Awadhi features, such as its verb endings (e.g., 'baranauṁ') and nominal forms, which are consistent with the language of Tulsidas's other major work, the Ramcharitmanas.\",\n",
    "    \"nigamana\": \"Therefore, the Hanuman Chalisa is written in the Awadhi language.\",\n",
    "    \"grounding_authority\": \"Philological Analysis & Comparative Linguistics\"\n",
    "  },\n",
    "  {\n",
    "    \"domain\": \"Comparative Philology / Grammar\",\n",
    "    \"pratijna\": \"The Awadhi of the Hanuman Chalisa is amenable to Pāṇinian grammatical analysis.\",\n",
    "    \"hetu\": \"Because Awadhi, as a Middle Indo-Aryan language, retains sufficient structural and lexical roots from Sanskrit.\",\n",
    "    \"udaharana\": \"Any descendant language that preserves the core grammatical categories and lexical roots of its parent language can be analyzed using the grammatical framework of the parent, just as Italian can be analyzed using the principles of Latin grammar.\",\n",
    "    \"upanaya\": \"The Awadhi text of the Hanuman Chalisa demonstrates this preservation, allowing for a systematic reconstruction of its verses into grammatically correct Classical Sanskrit by mapping its forms back to their Sanskrit origins (e.g., Awadhi 'jānike' to Sanskrit absolutive 'jñātvā').\",\n",
    "    \"nigamana\": \"Therefore, the Awadhi of the Hanuman Chalisa is amenable to Pāṇinian grammatical analysis.\",\n",
    "    \"grounding_authority\": \"The Comparative Method of Historical Linguistics / Pāṇinian Grammar\"\n",
    "  },\n",
    "  {\n",
    "    \"domain\": \"Comparative Philosophy / Epistemology\",\n",
    "    \"pratijna\": \"The opening verses of the Hanuman Chalisa employ a philosophical method of doubt.\",\n",
    "    \"hetu\": \"Because the speaker begins by declaring their own mind as impure and their intellect as deficient ('buddhihīna'), thereby clearing the ground for receiving higher knowledge.\",\n",
    "    \"udaharana\": \"Any philosophical method that begins by systematically doubting or negating the author's own certainty in order to establish a more secure foundation for truth is a method of doubt, as exemplified by Descartes' method in his 'Meditations,' which begins by doubting all sensory and rational knowledge.\",\n",
    "    \"upanaya\": \"The first two dohas of the Hanuman Chalisa exhibit this structure, with the speaker first needing to purify the 'mind-mirror' and then acknowledging being 'buddhihīna' (devoid of intelligence) before proceeding to narrate the pure glory of the divine.\",\n",
    "    \"nigamana\": \"Therefore, the opening verses of the Hanuman Chalisa employ a philosophical method of doubt.\",\n",
    "    \"grounding_authority\": \"Comparative Philosophy & Literary Analysis\"\n",
    "  },\n",
    "  {\n",
    "    \"domain\": \"Cultural History / Comparative Literature\",\n",
    "    \"pratijna\": \"The Hanuman Chalisa is a product of Hindu-Muslim cultural syncretism.\",\n",
    "    \"hetu\": \"Because it employs the Dohā meter, a poetic form of Persian origin, to convey Hindu devotional themes.\",\n",
    "    \"udaharana\": \"Whenever a cultural artifact combines formal elements from one tradition (like a poetic meter) with thematic content from another, it is an example of syncretism, as seen in the architecture of the Taj Mahal, which blends Persian and Mughal forms with Indian design elements.\",\n",
    "    \"upanaya\": \"The Hanuman Chalisa is such an artifact, using the Dohā couplet form, which was popularized in India through the influence of Persianate courtly literature, as the primary vehicle for a central Bhakti devotional text.\",\n",
    "    \"nigamana\": \"Therefore, the Hanuman Chalisa is a product of Hindu-Muslim cultural syncretism.\",\n",
    "    \"grounding_authority\": \"Comparative Literature & Cultural History\"\n",
    "  }\n",
    "]\n",
    "\n",
    "records: List[Dict[str, Any]] = [validate_record(r) for r in SEED_JSON]\n",
    "\n",
    "# Optional: attach lightweight source context from a local note if present\n",
    "src_note = SOURCES_DIR / 'iep' / 'al-ghazali_iep_20250815.txt'\n",
    "if src_note.exists():\n",
    "    try:\n",
    "        txt = src_note.read_text(encoding='utf-8')\n",
    "        header = '\\n'.join(txt.splitlines()[:10])\n",
    "        for r in records:\n",
    "            r['source'] = str(src_note)\n",
    "            r['notes'] = (r.get('notes') or '') + f\" | Context: {header}\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(f\"Loaded {len(records)} records for review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Pretty Printer for Nyaya Arguments\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "def show_record(r: Dict[str, Any], expand: bool=False) -> None:\n",
    "    status = r.get('status','queued')\n",
    "    color = {\n",
    "        'approved': 'green',\n",
    "        'edited': 'yellow',\n",
    "        'disapproved': 'red',\n",
    "        'queued': 'cyan'\n",
    "    }.get(status, 'cyan')\n",
    "\n",
    "    def trunc(s: str, n=400):\n",
    "        return s if expand or len(s) <= n else s[:n] + '…'\n",
    "\n",
    "    title = Text(f\"{r.get('domain','(no domain)')}  [{status}]\", style=f\"bold {color}\")\n",
    "    body = (\n",
    "        f\"[bold]Pratijna:[/bold] {trunc(r.get('pratijna',''))}\\n\"\n",
    "        f\"[bold]Hetu:[/bold] {trunc(r.get('hetu',''))}\\n\"\n",
    "        f\"[bold]Udaharana:[/bold] {trunc(r.get('udaharana',''))}\\n\"\n",
    "        f\"[bold]Upanaya:[/bold] {trunc(r.get('upanaya',''))}\\n\"\n",
    "        f\"[bold]Nigamana:[/bold] {trunc(r.get('nigamana',''))}\\n\"\n",
    "        f\"[bold]Authority:[/bold] {trunc(r.get('grounding_authority',''))}\\n\"\n",
    "    )\n",
    "    footer = f\"Source: {r.get('source','-')}\\nNotes: {trunc(r.get('notes',''))}\"\n",
    "    console.print(Panel.fit(body + \"\\n\" + footer, title=title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Interactive Review Widget (Approve / Disapprove / Edit)\n",
    "cur_idx = 0\n",
    "editor_visible = False\n",
    "\n",
    "out = Output()\n",
    "status_label = Label()\n",
    "btn_prev = Button(description='Prev', button_style='')\n",
    "btn_next = Button(description='Next', button_style='')\n",
    "btn_approve = Button(description='Approve', button_style='success')\n",
    "btn_disapprove = Button(description='Disapprove', button_style='danger')\n",
    "btn_edit = Button(description='Edit', button_style='warning')\n",
    "\n",
    "# 6) Edit Flow (Copy-Edit-Paste)\n",
    "edit_area = Textarea(placeholder='Record JSON here...', layout={'width':'100%','height':'200px'})\n",
    "btn_apply = Button(description='Apply Edit', button_style='warning')\n",
    "btn_cancel = Button(description='Cancel Edit', button_style='')\n",
    "\n",
    "progress = IntProgress(min=0, max=len(records), value=0, description='Reviewed')\n",
    "\n",
    "\n",
    "def refresh_view():\n",
    "    status_label.value = f\"Item {cur_idx+1}/{len(records)}\"\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        show_record(records[cur_idx])\n",
    "        if editor_visible:\n",
    "            print('\\n--- Edit JSON below (keep keys). ---')\n",
    "            print('Tip: Preserve the id; required fields must be present.')\n",
    "\n",
    "refresh_view()\n",
    "\n",
    "\n",
    "def on_prev(_):\n",
    "    global cur_idx\n",
    "    cur_idx = max(0, cur_idx-1)\n",
    "    refresh_view()\n",
    "\n",
    "def on_next(_):\n",
    "    global cur_idx\n",
    "    cur_idx = min(len(records)-1, cur_idx+1)\n",
    "    refresh_view()\n",
    "\n",
    "\n",
    "def persist(decision: str, before: Dict[str,Any], after: Optional[Dict[str,Any]]=None):\n",
    "    rec = after or before\n",
    "    row = {\n",
    "        'id': rec['id'],\n",
    "        'decision': decision,\n",
    "        'timestamp': datetime.utcnow().isoformat(),\n",
    "        'before': before,\n",
    "        'after': after or before,\n",
    "        'user': 'reviewer'\n",
    "    }\n",
    "    with open(LEDGER_PATH, 'a', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + '\\n')\n",
    "    # snapshot\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(SNAPSHOT_CSV, index=False)\n",
    "\n",
    "\n",
    "def on_approve(_):\n",
    "    r = records[cur_idx]\n",
    "    r['status'] = 'approved'\n",
    "    persist('approved', r)\n",
    "    progress.value = sum(1 for x in records if x['status'] != 'queued')\n",
    "    refresh_view()\n",
    "\n",
    "def on_disapprove(_):\n",
    "    r = records[cur_idx]\n",
    "    r['status'] = 'disapproved'\n",
    "    persist('disapproved', r)\n",
    "    progress.value = sum(1 for x in records if x['status'] != 'queued')\n",
    "    refresh_view()\n",
    "\n",
    "def on_edit(_):\n",
    "    global editor_visible\n",
    "    editor_visible = True\n",
    "    edit_area.value = json.dumps(records[cur_idx], ensure_ascii=False, indent=2)\n",
    "    refresh_view()\n",
    "\n",
    "\n",
    "def on_apply(_):\n",
    "    global editor_visible\n",
    "    try:\n",
    "        edited = json.loads(edit_area.value)\n",
    "        edited_id = records[cur_idx]['id']\n",
    "        before = copy.deepcopy(records[cur_idx])\n",
    "        # Preserve id\n",
    "        edited['id'] = edited_id\n",
    "        edited = validate_record(edited)\n",
    "        edited['status'] = 'edited'\n",
    "        records[cur_idx] = edited\n",
    "        persist('edited', before, edited)\n",
    "        editor_visible = False\n",
    "        progress.value = sum(1 for x in records if x['status'] != 'queued')\n",
    "        refresh_view()\n",
    "    except Exception as e:\n",
    "        out.append_stdout(f\"Edit error: {e}\\n\")\n",
    "\n",
    "\n",
    "def on_cancel(_):\n",
    "    global editor_visible\n",
    "    editor_visible = False\n",
    "    refresh_view()\n",
    "\n",
    "btn_prev.on_click(on_prev)\n",
    "btn_next.on_click(on_next)\n",
    "btn_approve.on_click(on_approve)\n",
    "btn_disapprove.on_click(on_disapprove)\n",
    "btn_edit.on_click(on_edit)\n",
    "btn_apply.on_click(on_apply)\n",
    "btn_cancel.on_click(on_cancel)\n",
    "\n",
    "ui = VBox([\n",
    "    HBox([status_label, progress]),\n",
    "    out,\n",
    "    HBox([btn_prev, btn_next, btn_approve, btn_disapprove, btn_edit]),\n",
    "    edit_area,\n",
    "    HBox([btn_apply, btn_cancel])\n",
    "])\n",
    "\n",
    "ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Decision Logging and Persistence (JSONL/CSV)\n",
    "print(f\"Ledger: {LEDGER_PATH}\")\n",
    "print(f\"Snapshot CSV: {SNAPSHOT_CSV}\")\n",
    "\n",
    "# Helper: write approved snapshot for this session\n",
    "\n",
    "def write_approved_snapshot(out_path: Path):\n",
    "    with out_path.open('w', encoding='utf-8') as f:\n",
    "        for r in records:\n",
    "            if r['status'] == 'approved' or r['status'] == 'edited':\n",
    "                f.write(json.dumps({k: r[k] for k in REQUIRED_FIELDS}, ensure_ascii=False) + '\\n')\n",
    "    print(f\"Wrote approved snapshot: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Batch Processing Loop and Progress Display\n",
    "# For this simple UI, the buttons control the loop manually.\n",
    "# Provide a one-click finalize step to write approved snapshot.\n",
    "from ipywidgets import Button as _Button\n",
    "btn_finalize = _Button(description='Finalize & Write Approved Snapshot', button_style='success')\n",
    "\n",
    "\n",
    "def on_finalize(_):\n",
    "    write_approved_snapshot(APPROVED_OUT)\n",
    "\n",
    "btn_finalize.on_click(on_finalize)\n",
    "btn_finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Hook to External Evaluator (Stub) and Iterative Improvement Queue\n",
    "IMPROVEMENT_THRESHOLD = 0.5\n",
    "\n",
    "improvement_queue: List[Dict[str, Any]] = []\n",
    "\n",
    "def evaluate(record: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    # Placeholder: could call an external CLI/API. Here, naive score by length of fields\n",
    "    score = sum(len(str(record.get(k,''))) for k in REQUIRED_FIELDS) / 2000.0\n",
    "    score = min(1.0, score)\n",
    "    feedback = 'OK' if score >= IMPROVEMENT_THRESHOLD else 'Needs elaboration or authority specificity.'\n",
    "    return {'score': score, 'feedback': feedback}\n",
    "\n",
    "# Evaluate current records and update improvement queue\n",
    "for r in records:\n",
    "    res = evaluate(r)\n",
    "    r['eval'] = res\n",
    "    if r.get('status') in {'disapproved'} or res['score'] < IMPROVEMENT_THRESHOLD:\n",
    "        prompt = {\n",
    "            'instruction': 'Improve the argument; add specificity to grounding_authority; strengthen hetu and examples.',\n",
    "            'record': {k: r.get(k) for k in REQUIRED_FIELDS},\n",
    "            'feedback': res['feedback'],\n",
    "            'context_hint': r.get('notes','')\n",
    "        }\n",
    "        improvement_queue.append(prompt)\n",
    "\n",
    "print(f\"Improvement queue size: {len(improvement_queue)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Resume From Saved State and Re-run + Smoke Tests\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_state(ledger_path: Path) -> List[Dict[str,Any]]:\n",
    "    if not ledger_path.exists():\n",
    "        return records\n",
    "    latest: Dict[str, Dict[str,Any]] = {}\n",
    "    with ledger_path.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                row = json.loads(line)\n",
    "                rid = row['id']\n",
    "                latest[rid] = row['after']\n",
    "            except Exception:\n",
    "                continue\n",
    "    id_to_idx = {r['id']: i for i,_r in enumerate(records)}\n",
    "    for rid, rec in latest.items():\n",
    "        if rid in id_to_idx:\n",
    "            records[id_to_idx[rid]] = rec\n",
    "    return records\n",
    "\n",
    "# Smoke tests\n",
    "assert all(k in records[0] for k in REQUIRED_FIELDS), 'required fields missing'\n",
    "write_approved_snapshot(SESSION_DIR / 'approved_smoketest.jsonl')\n",
    "show_record(records[0])\n",
    "print('Smoke tests passed. Resume ready.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
